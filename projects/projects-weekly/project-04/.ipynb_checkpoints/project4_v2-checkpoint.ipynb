{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#webscraping code from the link slack https://github.com/ashalan/glassdoor-salary-scraper/blob/master/scraper.py\n",
    "import time\n",
    "import json\n",
    "import Salary\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"\" # your email here\n",
    "password = \"\" # your password here\n",
    "\n",
    "# Manual options for the city, num pages to scrape, and URL\n",
    "pages = 6\n",
    "cityName = \"new-york-city\"\n",
    "cityURL = \"https://www.glassdoor.com/Salaries/new-york-city-data-scientist-salary-SRCH_IL.0,13_IM615_KO14,28.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_dict(obj):\n",
    "    return obj.__dict__\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_export(data)\n",
    "    jsonFile = open(cityName + \".json\", \"w\")\n",
    "    jsonFile.write(json.dumps(data, indent=4, separators=(',', ': '), default=obj_dict))\n",
    "    jsonFile.close()\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_driver():\n",
    "    driver = webdriver.Chrome(executable_path = \"./chromedriver\")\n",
    "    driver.wait = WebDriverWait(driver, 10)\n",
    "    return driver\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def login(driver, username, password):\n",
    "    driver.get(\"http://www.glassdoor.com/profile/login_input.htm\")\n",
    "    try:\n",
    "        user_field = driver.wait.until(EC.presence_of_element_located(\n",
    "            (By.NAME, \"username\")))\n",
    "        pw_field = driver.find_element_by_class_name(\"signin-password\")\n",
    "        login_button = driver.find_element_by_id(\"signInBtn\")\n",
    "        user_field.send_keys(username)\n",
    "        user_field.send_keys(Keys.TAB)\n",
    "        time.sleep(1)\n",
    "        pw_field.send_keys(password)\n",
    "        time.sleep(1)\n",
    "        login_button.click()\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException! Username/password field or login button not found on glassdoor.com\")\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_salaries_HTML(salaries, data):\n",
    "    for salary in salaries:\n",
    "        jobTitle = \"-\"\n",
    "        company = \"-\"\n",
    "        meanPay = \"-\"\n",
    "        jobTitle = salary.find(\"a\", { \"class\" : \"jobTitle\"}).getText().strip()\n",
    "        company = salary.find(\"div\", { \"class\" : \"i-emp\"}).getText().strip()\n",
    "        try:\n",
    "        meanPay = salary.find(\"div\", { \"class\" : \"meanPay\"}).find(\"strong\").getText().strip()\n",
    "        except:\n",
    "        meanPay = 'xxx'\n",
    "        r = Salary.Salary(jobTitle, company, meanPay)\n",
    "        data.append(r)\n",
    "    #endfor\n",
    "    return data\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(driver, URL, startPage, endPage, data, refresh):\n",
    "    if (startPage > endPage):\n",
    "        return data\n",
    "    #endif\n",
    "    print \"\\nPage \" + str(startPage) + \" of \" + str(endPage)\n",
    "    currentURL = URL + \"_IP\" + str(startPage) + \".htm\"\n",
    "    time.sleep(2)\n",
    "    #endif\n",
    "    if (refresh):\n",
    "        driver.get(currentURL)\n",
    "        print \"Getting \" + currentURL\n",
    "    #endif\n",
    "    time.sleep(2)\n",
    "    HTML = driver.page_source\n",
    "    soup = BeautifulSoup(HTML, \"html.parser\")\n",
    "    salaries = soup.find(\"div\", { \"class\" : [\"salaryChartModule\"] }).find_all(\"div\", { \"class\" : [\"salaryRow\"] })\n",
    "    if (salaries):\n",
    "        data = parse_salaries_HTML(salaries, data)\n",
    "        print \"Page \" + str(startPage) + \" scraped.\"\n",
    "        if (startPage % 10 == 0):\n",
    "            print \"\\nTaking a breather for a few seconds ...\"\n",
    "            time.sleep(10)\n",
    "        #endif\n",
    "        get_data(driver, URL, startPage + 1, endPage, data, True)\n",
    "    else:\n",
    "        print \"Waiting ... page still loading or CAPTCHA input required\"\n",
    "        time.sleep(3)\n",
    "        get_data(driver, URL, startPage, endPage, data, False)\n",
    "    #endif\n",
    "    return data\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    driver = init_driver()\n",
    "    time.sleep(3)\n",
    "    print \"Logging into Glassdoor account ...\"\n",
    "    login(driver, username, password)\n",
    "    time.sleep(10)\n",
    "    print \"\\nStarting data scraping ...\"\n",
    "    data = get_data(driver, cityURL[:-4], 1, pages, [], True)\n",
    "    print \"\\nExporting data to \" + cityName + \".json\"\n",
    "    json_export(data)\n",
    "    driver.quit()\n",
    "#endif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$66,843</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Canvas InfoTech</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$63,429</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>BetaSoft Systems</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$75,765</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay          jobTitle           company       location\n",
       "0  $66,843  Business Analyst   Canvas InfoTech  San Francisco\n",
       "1  $63,429  Business Analyst  BetaSoft Systems  San Francisco\n",
       "2  $75,765  Business Analyst          Deloitte  San Francisco"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"/Users/Debjani/Downloads/SanFranciscoBA.csv\")\n",
    "df1[\"location\"] = \"San Francisco\"\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$65,819</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>JSMN International</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$75,262</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$81,734</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay          jobTitle             company  location\n",
       "0  $65,819  Business Analyst  JSMN International  New York\n",
       "1  $75,262  Business Analyst            Deloitte  New York\n",
       "2  $81,734  Business Analyst         J.P. Morgan  New York"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/Users/Debjani/Downloads/NewYorkBA.csv\")\n",
    "df2[\"location\"] = \"New York\"\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$31.19</td>\n",
       "      <td>Business Analyst - Hourly</td>\n",
       "      <td>Xceltech</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$67,164</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Akvarr</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$31.46</td>\n",
       "      <td>Business Analyst - Hourly</td>\n",
       "      <td>Enterprise Business Solutions</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay                   jobTitle                        company location\n",
       "0   $31.19  Business Analyst - Hourly                       Xceltech       DC\n",
       "1  $67,164           Business Analyst                         Akvarr       DC\n",
       "2   $31.46  Business Analyst - Hourly  Enterprise Business Solutions       DC"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"/Users/Debjani/Downloads/DCBA.csv\")\n",
    "df3[\"location\"] = \"DC\"\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$69,808</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>State Street</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$72,585</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$47,878</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Public Consulting Group</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay          jobTitle                  company location\n",
       "0  $69,808  Business Analyst             State Street   Boston\n",
       "1  $72,585  Business Analyst                 Deloitte   Boston\n",
       "2  $47,878  Business Analyst  Public Consulting Group   Boston"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"/Users/Debjani/Downloads/BostonBA.csv\")\n",
    "df4[\"location\"] = \"Boston\"\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$96,829</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$103,271</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Zynga</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$61,438</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Canvas InfoTech</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanPay      jobTitle          company       location\n",
       "0   $96,829  Data Analyst         Esurance  San Francisco\n",
       "1  $103,271  Data Analyst            Zynga  San Francisco\n",
       "2   $61,438  Data Analyst  Canvas InfoTech  San Francisco"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/Users/Debjani/Downloads/SanFranciscoDataAna.csv\")\n",
    "df5[\"location\"] = \"San Francisco\"\n",
    "df5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$68,746</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bloomberg L.P.</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$62,209</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gabriels Technology Solutions</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$119,786</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Vitech Systems Group</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanPay      jobTitle                        company  location\n",
       "0   $68,746  Data Analyst                 Bloomberg L.P.  New York\n",
       "1   $62,209  Data Analyst  Gabriels Technology Solutions  New York\n",
       "2  $119,786  Data Analyst           Vitech Systems Group  New York"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"/Users/Debjani/Downloads/NYDataAna.csv\")\n",
    "df6[\"location\"] = \"New York\"\n",
    "df6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$64,757</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>comScore</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$67,459</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$59,495</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>EDGAR Online</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay      jobTitle       company location\n",
       "0  $64,757  Data Analyst      comScore       DC\n",
       "1  $67,459  Data Analyst   Capital One       DC\n",
       "2  $59,495  Data Analyst  EDGAR Online       DC"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.read_csv(\"/Users/Debjani/Downloads/DCDataAna.csv\")\n",
    "df7[\"location\"] = \"DC\"\n",
    "df7.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$70,835</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Liberty Mutual Insurance</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$56,658</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Compete, Inc</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$55,619</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanPay      jobTitle                   company location\n",
       "0  $70,835  Data Analyst  Liberty Mutual Insurance   Boston\n",
       "1  $56,658  Data Analyst              Compete, Inc   Boston\n",
       "2  $55,619  Data Analyst         Boston University   Boston"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = pd.read_csv(\"/Users/Debjani/Downloads/BostonDataAna.csv\")\n",
    "df8[\"location\"] = \"Boston\"\n",
    "df8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$139,144</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$123,724</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$134,861</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanPay        jobTitle   company       location\n",
       "0  $139,144  Data Scientist  Facebook  San Francisco\n",
       "1  $123,724  Data Scientist    Airbnb  San Francisco\n",
       "2  $134,861  Data Scientist   Twitter  San Francisco"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9 = pd.read_csv(\"/Users/Debjani/Downloads/SanFranciscoDS.csv\")\n",
    "df9[\"location\"] = \"San Francisco\"\n",
    "df9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$104,714</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AIG</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$136,000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Knewton</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$101,667</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Audible</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanPay        jobTitle  company  location\n",
       "0  $104,714  Data Scientist      AIG  New York\n",
       "1  $136,000  Data Scientist  Knewton  New York\n",
       "2  $101,667  Data Scientist  Audible  New York"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10 = pd.read_csv(\"/Users/Debjani/Downloads/NYDS.csv\")\n",
    "df10[\"location\"] = \"New York\"\n",
    "df10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$104k - $113k</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$97k - $104k</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$98k - $107k</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>MITRE</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         meanPay               jobTitle           company location\n",
       "0  $104k - $113k  Junior Data Scientist           Verizon       DC\n",
       "1   $97k - $104k  Junior Data Scientist  Verizon Wireless       DC\n",
       "2   $98k - $107k  Junior Data Scientist             MITRE       DC"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11 = pd.read_csv(\"/Users/Debjani/Downloads/DCDS.csv\")\n",
    "df11[\"location\"] = \"DC\"\n",
    "df11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$94,496</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wayfair</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$119,000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$106,250</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>TrueMotion</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meanPay        jobTitle      company location\n",
       "0   $94,496  Data Scientist      Wayfair   Boston\n",
       "1  $119,000  Data Scientist  TripAdvisor   Boston\n",
       "2  $106,250  Data Scientist   TrueMotion   Boston"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12 = pd.read_csv(\"/Users/Debjani/Downloads/BostonDS.csv\")\n",
    "df12[\"location\"] = \"Boston\"\n",
    "df12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   meanPay                   jobTitle             company       location\n",
      "0  $66,843           Business Analyst     Canvas InfoTech  San Francisco\n",
      "1  $63,429           Business Analyst    BetaSoft Systems  San Francisco\n",
      "2  $75,765           Business Analyst            Deloitte  San Francisco\n",
      "3   $43.70  Business Analyst - Hourly             Infosys  San Francisco\n",
      "4  $81,972           Business Analyst  McKinsey & Company  San Francisco\n"
     ]
    }
   ],
   "source": [
    "#joining all the data frames together\n",
    "\n",
    "ndf = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12])\n",
    "ndf = ndf.reset_index(drop=True)\n",
    "print ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1111 entries, 0 to 1110\n",
      "Data columns (total 4 columns):\n",
      "meanPay     1111 non-null object\n",
      "jobTitle    1111 non-null object\n",
      "company     1111 non-null object\n",
      "location    1111 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ndf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business Analyst', 'Business Analyst - Hourly',\n",
       "       'Business Analyst - Hourly Contractor',\n",
       "       'Business Analyst Intern - Hourly',\n",
       "       'Business Analyst Intern - Monthly', 'Data Analyst',\n",
       "       'Data Analyst Intern - Hourly', 'Data Analyst - Hourly',\n",
       "       'Data Analyst - Hourly Contractor', 'Data and Policy Analyst',\n",
       "       'Network Systems and Data Communications Analyst',\n",
       "       'Data Warehouse Analyst', 'Senior Data Analyst',\n",
       "       'Principal Data Analyst', 'Data Analyst Manager',\n",
       "       'Data Systems Analyst', 'Software Engineer/Data Analyst',\n",
       "       'Data and Policy Analyst I', 'Weka Data Analyst',\n",
       "       'Clinical Data Analyst', 'Quantitative Data Analyst',\n",
       "       'Business Data Analyst', 'Data Analyst I',\n",
       "       'Finance Data Management Analyst', 'Data Analyst II',\n",
       "       'Clinical Data Analyst/Manager', 'Chemical Data Systems Analyst',\n",
       "       'Business Data Analyst II', 'Research/Data Analyst',\n",
       "       'Data Scientist', 'Data Scientist Intern - Monthly',\n",
       "       'Data Scientist Intern - Hourly', 'Senior Data Scientist',\n",
       "       'Clinical Laboratory Scientist-data Analyst',\n",
       "       'Senior Data Scientist/Statistician',\n",
       "       'Scientist, Statistical and Data Sciences',\n",
       "       'Principal Data Scientist', 'Data Visualization Scientist',\n",
       "       'Staff Data Scientist', 'Entry Level Data Scientist',\n",
       "       'Data Scientist II', 'Junior Data Scientist',\n",
       "       'Chief Data Scientist', 'Data Scientist Intern'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf[\"jobTitle\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst', 'Data Scientist'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating two buckets for the job title: Data Analyst and Data Scientist\n",
    "\n",
    "def clean_cat(x):\n",
    "    if \"Analyst\" in x:\n",
    "        return \"Data Analyst\"\n",
    "    elif \"Scientist\" in x:\n",
    "        return \"Data Scientist\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "ndf[\"jobTitle\"]= ndf[\"jobTitle\"].apply(clean_cat)\n",
    "ndf[\"jobTitle\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        meanPay        jobTitle                           company  \\\n",
      "0      66843.00    Data Analyst                   Canvas InfoTech   \n",
      "1      63429.00    Data Analyst                  BetaSoft Systems   \n",
      "2      75765.00    Data Analyst                          Deloitte   \n",
      "3         43.70    Data Analyst                           Infosys   \n",
      "4      81972.00    Data Analyst                McKinsey & Company   \n",
      "5      74301.00    Data Analyst                         Accenture   \n",
      "6      76798.00    Data Analyst                Hitachi Consulting   \n",
      "7      63146.00    Data Analyst             All State Consultants   \n",
      "8         31.82    Data Analyst  Business Intelligence Associates   \n",
      "9         31.48    Data Analyst                          Xceltech   \n",
      "10     68889.00    Data Analyst                  DGN Technologies   \n",
      "11        31.82    Data Analyst     Enterprise Business Solutions   \n",
      "12        31.09    Data Analyst                   Agama Solutions   \n",
      "13     81637.00    Data Analyst                Calypso Technology   \n",
      "14     69434.00    Data Analyst                      DS Soft Tech   \n",
      "15    100753.00    Data Analyst                           Chevron   \n",
      "16     82388.00    Data Analyst          Pacific Gas and Electric   \n",
      "17     64966.00    Data Analyst                          Equinett   \n",
      "18        32.12    Data Analyst                             Agama   \n",
      "19        30.49    Data Analyst                            ecalix   \n",
      "20     69238.00    Data Analyst                              Cswl   \n",
      "21     83102.00    Data Analyst                   Mahindra Satyam   \n",
      "22     83872.00    Data Analyst                 Kaiser Permanente   \n",
      "23     82177.00    Data Analyst                         Visa Inc.   \n",
      "24     70627.00    Data Analyst                           Detecon   \n",
      "25     66690.00    Data Analyst               ProSwift Consulting   \n",
      "26    122404.00    Data Analyst                     Cisco Systems   \n",
      "27     87809.00    Data Analyst                       Cognilytics   \n",
      "28     64794.00    Data Analyst                         Macro.Net   \n",
      "29     85728.00    Data Analyst                            Oracle   \n",
      "...         ...             ...                               ...   \n",
      "1081  112000.00  Data Scientist                        Amazon.com   \n",
      "1082   87000.00  Data Scientist                            ViaSat   \n",
      "1083  150000.00  Data Scientist                         Think Big   \n",
      "1084  126000.00  Data Scientist                        BNY Mellon   \n",
      "1085  132000.00  Data Scientist                               IBM   \n",
      "1086  144000.00  Data Scientist                         Microsoft   \n",
      "1087   93000.00  Data Scientist               Booz Allen Hamilton   \n",
      "1088  136000.00  Data Scientist                         Think Big   \n",
      "1089   98000.00  Data Scientist                          MaxPoint   \n",
      "1090  110000.00  Data Scientist                   Tiger Analytics   \n",
      "1091  134000.00  Data Scientist                              YuMe   \n",
      "1092  116000.00  Data Scientist                               FIS   \n",
      "1093  142000.00  Data Scientist                            Akamai   \n",
      "1094  111000.00  Data Scientist                        Amazon.com   \n",
      "1095   87000.00  Data Scientist                            ViaSat   \n",
      "1096  151000.00  Data Scientist                         Think Big   \n",
      "1097  128000.00  Data Scientist                        BNY Mellon   \n",
      "1098  131000.00  Data Scientist                               IBM   \n",
      "1099  146000.00  Data Scientist                         Microsoft   \n",
      "1100   93000.00  Data Scientist               Booz Allen Hamilton   \n",
      "1101  133000.00  Data Scientist                         Think Big   \n",
      "1102   98000.00  Data Scientist                          MaxPoint   \n",
      "1103  110000.00  Data Scientist                   Tiger Analytics   \n",
      "1104  132000.00  Data Scientist                              YuMe   \n",
      "1105  116000.00  Data Scientist                               FIS   \n",
      "1106  143000.00  Data Scientist                            Akamai   \n",
      "1107  112000.00  Data Scientist                        Amazon.com   \n",
      "1108   87000.00  Data Scientist                            ViaSat   \n",
      "1109  150000.00  Data Scientist                         Think Big   \n",
      "1110  128000.00  Data Scientist                        BNY Mellon   \n",
      "\n",
      "           location  \n",
      "0     San Francisco  \n",
      "1     San Francisco  \n",
      "2     San Francisco  \n",
      "3     San Francisco  \n",
      "4     San Francisco  \n",
      "5     San Francisco  \n",
      "6     San Francisco  \n",
      "7     San Francisco  \n",
      "8     San Francisco  \n",
      "9     San Francisco  \n",
      "10    San Francisco  \n",
      "11    San Francisco  \n",
      "12    San Francisco  \n",
      "13    San Francisco  \n",
      "14    San Francisco  \n",
      "15    San Francisco  \n",
      "16    San Francisco  \n",
      "17    San Francisco  \n",
      "18    San Francisco  \n",
      "19    San Francisco  \n",
      "20    San Francisco  \n",
      "21    San Francisco  \n",
      "22    San Francisco  \n",
      "23    San Francisco  \n",
      "24    San Francisco  \n",
      "25    San Francisco  \n",
      "26    San Francisco  \n",
      "27    San Francisco  \n",
      "28    San Francisco  \n",
      "29    San Francisco  \n",
      "...             ...  \n",
      "1081         Boston  \n",
      "1082         Boston  \n",
      "1083         Boston  \n",
      "1084         Boston  \n",
      "1085         Boston  \n",
      "1086         Boston  \n",
      "1087         Boston  \n",
      "1088         Boston  \n",
      "1089         Boston  \n",
      "1090         Boston  \n",
      "1091         Boston  \n",
      "1092         Boston  \n",
      "1093         Boston  \n",
      "1094         Boston  \n",
      "1095         Boston  \n",
      "1096         Boston  \n",
      "1097         Boston  \n",
      "1098         Boston  \n",
      "1099         Boston  \n",
      "1100         Boston  \n",
      "1101         Boston  \n",
      "1102         Boston  \n",
      "1103         Boston  \n",
      "1104         Boston  \n",
      "1105         Boston  \n",
      "1106         Boston  \n",
      "1107         Boston  \n",
      "1108         Boston  \n",
      "1109         Boston  \n",
      "1110         Boston  \n",
      "\n",
      "[1110 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      meanPay                   jobTitle                           company  \\\n",
      "0       66843           Business Analyst                   Canvas InfoTech   \n",
      "1       63429           Business Analyst                  BetaSoft Systems   \n",
      "2       75765           Business Analyst                          Deloitte   \n",
      "3       43.70  Business Analyst - Hourly                           Infosys   \n",
      "4       81972           Business Analyst                McKinsey & Company   \n",
      "5       74301           Business Analyst                         Accenture   \n",
      "6       76798           Business Analyst                Hitachi Consulting   \n",
      "7       63146           Business Analyst             All State Consultants   \n",
      "8       31.82  Business Analyst - Hourly  Business Intelligence Associates   \n",
      "9       31.48  Business Analyst - Hourly                          Xceltech   \n",
      "10      68889           Business Analyst                  DGN Technologies   \n",
      "11      31.82  Business Analyst - Hourly     Enterprise Business Solutions   \n",
      "12      31.09  Business Analyst - Hourly                   Agama Solutions   \n",
      "13      81637           Business Analyst                Calypso Technology   \n",
      "14      69434           Business Analyst                      DS Soft Tech   \n",
      "15     100753           Business Analyst                           Chevron   \n",
      "16      82388           Business Analyst          Pacific Gas and Electric   \n",
      "17      64966           Business Analyst                          Equinett   \n",
      "18      32.12  Business Analyst - Hourly                             Agama   \n",
      "19      30.49  Business Analyst - Hourly                            ecalix   \n",
      "20      69238           Business Analyst                              Cswl   \n",
      "21      83102           Business Analyst                   Mahindra Satyam   \n",
      "22      83872           Business Analyst                 Kaiser Permanente   \n",
      "23      82177           Business Analyst                         Visa Inc.   \n",
      "24      70627           Business Analyst                           Detecon   \n",
      "25      66690           Business Analyst               ProSwift Consulting   \n",
      "26     122404           Business Analyst                     Cisco Systems   \n",
      "27      87809           Business Analyst                       Cognilytics   \n",
      "28      64794           Business Analyst                         Macro.Net   \n",
      "29      85728           Business Analyst                            Oracle   \n",
      "...       ...                        ...                               ...   \n",
      "1081  108-116      Data Scientist Intern                        Amazon.com   \n",
      "1082    84-90      Data Scientist Intern                            ViaSat   \n",
      "1083  144-157   Principal Data Scientist                         Think Big   \n",
      "1084  122-131   Principal Data Scientist                        BNY Mellon   \n",
      "1085  126-138      Senior Data Scientist                               IBM   \n",
      "1086  139-150      Senior Data Scientist                         Microsoft   \n",
      "1087    89-97      Senior Data Scientist               Booz Allen Hamilton   \n",
      "1088  131-141      Senior Data Scientist                         Think Big   \n",
      "1089   94-102      Senior Data Scientist                          MaxPoint   \n",
      "1090  106-114      Senior Data Scientist                   Tiger Analytics   \n",
      "1091  129-139      Senior Data Scientist                              YuMe   \n",
      "1092  111-122      Senior Data Scientist                               FIS   \n",
      "1093  136-149      Senior Data Scientist                            Akamai   \n",
      "1094  107-116      Data Scientist Intern                        Amazon.com   \n",
      "1095    84-91      Data Scientist Intern                            ViaSat   \n",
      "1096  146-156   Principal Data Scientist                         Think Big   \n",
      "1097  122-134   Principal Data Scientist                        BNY Mellon   \n",
      "1098  126-136      Senior Data Scientist                               IBM   \n",
      "1099  139-153      Senior Data Scientist                         Microsoft   \n",
      "1100    89-97      Senior Data Scientist               Booz Allen Hamilton   \n",
      "1101  128-139      Senior Data Scientist                         Think Big   \n",
      "1102   94-103      Senior Data Scientist                          MaxPoint   \n",
      "1103  106-114      Senior Data Scientist                   Tiger Analytics   \n",
      "1104  127-138      Senior Data Scientist                              YuMe   \n",
      "1105  112-121      Senior Data Scientist                               FIS   \n",
      "1106  137-149      Senior Data Scientist                            Akamai   \n",
      "1107  108-116      Data Scientist Intern                        Amazon.com   \n",
      "1108    83-91      Data Scientist Intern                            ViaSat   \n",
      "1109  144-157   Principal Data Scientist                         Think Big   \n",
      "1110  123-133   Principal Data Scientist                        BNY Mellon   \n",
      "\n",
      "           location  \n",
      "0     San Francisco  \n",
      "1     San Francisco  \n",
      "2     San Francisco  \n",
      "3     San Francisco  \n",
      "4     San Francisco  \n",
      "5     San Francisco  \n",
      "6     San Francisco  \n",
      "7     San Francisco  \n",
      "8     San Francisco  \n",
      "9     San Francisco  \n",
      "10    San Francisco  \n",
      "11    San Francisco  \n",
      "12    San Francisco  \n",
      "13    San Francisco  \n",
      "14    San Francisco  \n",
      "15    San Francisco  \n",
      "16    San Francisco  \n",
      "17    San Francisco  \n",
      "18    San Francisco  \n",
      "19    San Francisco  \n",
      "20    San Francisco  \n",
      "21    San Francisco  \n",
      "22    San Francisco  \n",
      "23    San Francisco  \n",
      "24    San Francisco  \n",
      "25    San Francisco  \n",
      "26    San Francisco  \n",
      "27    San Francisco  \n",
      "28    San Francisco  \n",
      "29    San Francisco  \n",
      "...             ...  \n",
      "1081         Boston  \n",
      "1082         Boston  \n",
      "1083         Boston  \n",
      "1084         Boston  \n",
      "1085         Boston  \n",
      "1086         Boston  \n",
      "1087         Boston  \n",
      "1088         Boston  \n",
      "1089         Boston  \n",
      "1090         Boston  \n",
      "1091         Boston  \n",
      "1092         Boston  \n",
      "1093         Boston  \n",
      "1094         Boston  \n",
      "1095         Boston  \n",
      "1096         Boston  \n",
      "1097         Boston  \n",
      "1098         Boston  \n",
      "1099         Boston  \n",
      "1100         Boston  \n",
      "1101         Boston  \n",
      "1102         Boston  \n",
      "1103         Boston  \n",
      "1104         Boston  \n",
      "1105         Boston  \n",
      "1106         Boston  \n",
      "1107         Boston  \n",
      "1108         Boston  \n",
      "1109         Boston  \n",
      "1110         Boston  \n",
      "\n",
      "[1111 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ndf['meanPay'] = ndf['meanPay'].str.replace('\\$', '').str.replace('\\-', '').str.replace('\\k', '').str.replace('\\,', '')\n",
    "ndf['meanPay'] = ndf['meanPay'].str.replace('  ', '-')\n",
    "print ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_sal(x):\n",
    "    if '-' in x and len(x)==5:\n",
    "        return ((int(x[0:2])+int(x[3:5]))/2)*1000\n",
    "    elif '-' in x and len(x)==6:\n",
    "        return ((int(x[0:2])+int(x[3:6]))/2)*1000\n",
    "    elif '-' in x and len(x)==7:\n",
    "        return ((int(x[0:3])+int(x[4:7]))/2)*1000\n",
    "    else:\n",
    "        return x\n",
    "ndf['meanPay'] = ndf['meanPay'].map(mean_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndf = ndf[ndf['meanPay']!='8-8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndf['meanPay'] = ndf['meanPay'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        meanPay        jobTitle                           company  \\\n",
      "0      66843.00    Data Analyst                   Canvas InfoTech   \n",
      "1      63429.00    Data Analyst                  BetaSoft Systems   \n",
      "2      75765.00    Data Analyst                          Deloitte   \n",
      "3         43.70    Data Analyst                           Infosys   \n",
      "4      81972.00    Data Analyst                McKinsey & Company   \n",
      "5      74301.00    Data Analyst                         Accenture   \n",
      "6      76798.00    Data Analyst                Hitachi Consulting   \n",
      "7      63146.00    Data Analyst             All State Consultants   \n",
      "8         31.82    Data Analyst  Business Intelligence Associates   \n",
      "9         31.48    Data Analyst                          Xceltech   \n",
      "10     68889.00    Data Analyst                  DGN Technologies   \n",
      "11        31.82    Data Analyst     Enterprise Business Solutions   \n",
      "12        31.09    Data Analyst                   Agama Solutions   \n",
      "13     81637.00    Data Analyst                Calypso Technology   \n",
      "14     69434.00    Data Analyst                      DS Soft Tech   \n",
      "15    100753.00    Data Analyst                           Chevron   \n",
      "16     82388.00    Data Analyst          Pacific Gas and Electric   \n",
      "17     64966.00    Data Analyst                          Equinett   \n",
      "18        32.12    Data Analyst                             Agama   \n",
      "19        30.49    Data Analyst                            ecalix   \n",
      "20     69238.00    Data Analyst                              Cswl   \n",
      "21     83102.00    Data Analyst                   Mahindra Satyam   \n",
      "22     83872.00    Data Analyst                 Kaiser Permanente   \n",
      "23     82177.00    Data Analyst                         Visa Inc.   \n",
      "24     70627.00    Data Analyst                           Detecon   \n",
      "25     66690.00    Data Analyst               ProSwift Consulting   \n",
      "26    122404.00    Data Analyst                     Cisco Systems   \n",
      "27     87809.00    Data Analyst                       Cognilytics   \n",
      "28     64794.00    Data Analyst                         Macro.Net   \n",
      "29     85728.00    Data Analyst                            Oracle   \n",
      "...         ...             ...                               ...   \n",
      "1081  112000.00  Data Scientist                        Amazon.com   \n",
      "1082   87000.00  Data Scientist                            ViaSat   \n",
      "1083  150000.00  Data Scientist                         Think Big   \n",
      "1084  126000.00  Data Scientist                        BNY Mellon   \n",
      "1085  132000.00  Data Scientist                               IBM   \n",
      "1086  144000.00  Data Scientist                         Microsoft   \n",
      "1087   93000.00  Data Scientist               Booz Allen Hamilton   \n",
      "1088  136000.00  Data Scientist                         Think Big   \n",
      "1089   98000.00  Data Scientist                          MaxPoint   \n",
      "1090  110000.00  Data Scientist                   Tiger Analytics   \n",
      "1091  134000.00  Data Scientist                              YuMe   \n",
      "1092  116000.00  Data Scientist                               FIS   \n",
      "1093  142000.00  Data Scientist                            Akamai   \n",
      "1094  111000.00  Data Scientist                        Amazon.com   \n",
      "1095   87000.00  Data Scientist                            ViaSat   \n",
      "1096  151000.00  Data Scientist                         Think Big   \n",
      "1097  128000.00  Data Scientist                        BNY Mellon   \n",
      "1098  131000.00  Data Scientist                               IBM   \n",
      "1099  146000.00  Data Scientist                         Microsoft   \n",
      "1100   93000.00  Data Scientist               Booz Allen Hamilton   \n",
      "1101  133000.00  Data Scientist                         Think Big   \n",
      "1102   98000.00  Data Scientist                          MaxPoint   \n",
      "1103  110000.00  Data Scientist                   Tiger Analytics   \n",
      "1104  132000.00  Data Scientist                              YuMe   \n",
      "1105  116000.00  Data Scientist                               FIS   \n",
      "1106  143000.00  Data Scientist                            Akamai   \n",
      "1107  112000.00  Data Scientist                        Amazon.com   \n",
      "1108   87000.00  Data Scientist                            ViaSat   \n",
      "1109  150000.00  Data Scientist                         Think Big   \n",
      "1110  128000.00  Data Scientist                        BNY Mellon   \n",
      "\n",
      "           location  \n",
      "0     San Francisco  \n",
      "1     San Francisco  \n",
      "2     San Francisco  \n",
      "3     San Francisco  \n",
      "4     San Francisco  \n",
      "5     San Francisco  \n",
      "6     San Francisco  \n",
      "7     San Francisco  \n",
      "8     San Francisco  \n",
      "9     San Francisco  \n",
      "10    San Francisco  \n",
      "11    San Francisco  \n",
      "12    San Francisco  \n",
      "13    San Francisco  \n",
      "14    San Francisco  \n",
      "15    San Francisco  \n",
      "16    San Francisco  \n",
      "17    San Francisco  \n",
      "18    San Francisco  \n",
      "19    San Francisco  \n",
      "20    San Francisco  \n",
      "21    San Francisco  \n",
      "22    San Francisco  \n",
      "23    San Francisco  \n",
      "24    San Francisco  \n",
      "25    San Francisco  \n",
      "26    San Francisco  \n",
      "27    San Francisco  \n",
      "28    San Francisco  \n",
      "29    San Francisco  \n",
      "...             ...  \n",
      "1081         Boston  \n",
      "1082         Boston  \n",
      "1083         Boston  \n",
      "1084         Boston  \n",
      "1085         Boston  \n",
      "1086         Boston  \n",
      "1087         Boston  \n",
      "1088         Boston  \n",
      "1089         Boston  \n",
      "1090         Boston  \n",
      "1091         Boston  \n",
      "1092         Boston  \n",
      "1093         Boston  \n",
      "1094         Boston  \n",
      "1095         Boston  \n",
      "1096         Boston  \n",
      "1097         Boston  \n",
      "1098         Boston  \n",
      "1099         Boston  \n",
      "1100         Boston  \n",
      "1101         Boston  \n",
      "1102         Boston  \n",
      "1103         Boston  \n",
      "1104         Boston  \n",
      "1105         Boston  \n",
      "1106         Boston  \n",
      "1107         Boston  \n",
      "1108         Boston  \n",
      "1109         Boston  \n",
      "1110         Boston  \n",
      "\n",
      "[1110 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1119af390>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAESCAYAAAAWtRmOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzNr8f8Bt25BTnHp/LwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a04110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ndf[\"meanPay\"].hist()\n",
    "pl.suptitle(\"meanPay Histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the meanPay:  80760.2707117\n",
      "median of the meanPay:  74000.0\n",
      "stdv of the meanPay:  34651.0334318\n",
      "miminum meanPay:  13.0\n",
      "maximum meanPay:  209000.0\n"
     ]
    }
   ],
   "source": [
    "print \"mean of the meanPay: \", ndf['meanPay'].mean()\n",
    "print \"median of the meanPay: \", ndf['meanPay'].median()\n",
    "print \"stdv of the meanPay: \", ndf['meanPay'].std()\n",
    "print \"miminum meanPay: \", ndf['meanPay'].min()\n",
    "print \"maximum meanPay: \", ndf['meanPay'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanPay</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66843.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Canvas InfoTech</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63429.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>BetaSoft Systems</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75765.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81972.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74301.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76798.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hitachi Consulting</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63146.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>All State Consultants</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68889.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>DGN Technologies</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81637.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Calypso Technology</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>69434.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>DS Soft Tech</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100753.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82388.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pacific Gas and Electric</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64966.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Equinett</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69238.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cswl</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>83102.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mahindra Satyam</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83872.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82177.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70627.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Detecon</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>66690.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ProSwift Consulting</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>122404.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cisco Systems</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87809.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognilytics</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64794.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Macro.Net</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>85728.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66598.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sandlenet</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68283.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>DYNASOFT SYNERGY</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>79981.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>71657.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Safeway</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80901.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Genentech</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>68960.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>63805.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Agile Informatics</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>112000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>87000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ViaSat</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think Big</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>126000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BNY Mellon</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>132000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>144000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>93000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>136000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think Big</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>98000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MaxPoint</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>110000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>134000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>YuMe</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>116000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FIS</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>142000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Akamai</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>111000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>87000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ViaSat</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>151000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think Big</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>128000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BNY Mellon</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>131000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>146000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>93000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>133000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think Big</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>98000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MaxPoint</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>110000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>132000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>YuMe</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>116000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FIS</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>143000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Akamai</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>112000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>87000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ViaSat</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think Big</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>128000.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BNY Mellon</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       meanPay        jobTitle                         company       location\n",
       "0      66843.0    Data Analyst                 Canvas InfoTech  San Francisco\n",
       "1      63429.0    Data Analyst                BetaSoft Systems  San Francisco\n",
       "2      75765.0    Data Analyst                        Deloitte  San Francisco\n",
       "3      81972.0    Data Analyst              McKinsey & Company  San Francisco\n",
       "4      74301.0    Data Analyst                       Accenture  San Francisco\n",
       "5      76798.0    Data Analyst              Hitachi Consulting  San Francisco\n",
       "6      63146.0    Data Analyst           All State Consultants  San Francisco\n",
       "7      68889.0    Data Analyst                DGN Technologies  San Francisco\n",
       "8      81637.0    Data Analyst              Calypso Technology  San Francisco\n",
       "9      69434.0    Data Analyst                    DS Soft Tech  San Francisco\n",
       "10    100753.0    Data Analyst                         Chevron  San Francisco\n",
       "11     82388.0    Data Analyst        Pacific Gas and Electric  San Francisco\n",
       "12     64966.0    Data Analyst                        Equinett  San Francisco\n",
       "13     69238.0    Data Analyst                            Cswl  San Francisco\n",
       "14     83102.0    Data Analyst                 Mahindra Satyam  San Francisco\n",
       "15     83872.0    Data Analyst               Kaiser Permanente  San Francisco\n",
       "16     82177.0    Data Analyst                       Visa Inc.  San Francisco\n",
       "17     70627.0    Data Analyst                         Detecon  San Francisco\n",
       "18     66690.0    Data Analyst             ProSwift Consulting  San Francisco\n",
       "19    122404.0    Data Analyst                   Cisco Systems  San Francisco\n",
       "20     87809.0    Data Analyst                     Cognilytics  San Francisco\n",
       "21     64794.0    Data Analyst                       Macro.Net  San Francisco\n",
       "22     85728.0    Data Analyst                          Oracle  San Francisco\n",
       "23     66598.0    Data Analyst                       Sandlenet  San Francisco\n",
       "24     68283.0    Data Analyst                DYNASOFT SYNERGY  San Francisco\n",
       "25     79981.0    Data Analyst                     Wells Fargo  San Francisco\n",
       "26     71657.0    Data Analyst                         Safeway  San Francisco\n",
       "27     80901.0    Data Analyst                       Genentech  San Francisco\n",
       "28     68960.0    Data Analyst  Cognizant Technology Solutions  San Francisco\n",
       "29     63805.0    Data Analyst               Agile Informatics  San Francisco\n",
       "...        ...             ...                             ...            ...\n",
       "1021  112000.0  Data Scientist                      Amazon.com         Boston\n",
       "1022   87000.0  Data Scientist                          ViaSat         Boston\n",
       "1023  150000.0  Data Scientist                       Think Big         Boston\n",
       "1024  126000.0  Data Scientist                      BNY Mellon         Boston\n",
       "1025  132000.0  Data Scientist                             IBM         Boston\n",
       "1026  144000.0  Data Scientist                       Microsoft         Boston\n",
       "1027   93000.0  Data Scientist             Booz Allen Hamilton         Boston\n",
       "1028  136000.0  Data Scientist                       Think Big         Boston\n",
       "1029   98000.0  Data Scientist                        MaxPoint         Boston\n",
       "1030  110000.0  Data Scientist                 Tiger Analytics         Boston\n",
       "1031  134000.0  Data Scientist                            YuMe         Boston\n",
       "1032  116000.0  Data Scientist                             FIS         Boston\n",
       "1033  142000.0  Data Scientist                          Akamai         Boston\n",
       "1034  111000.0  Data Scientist                      Amazon.com         Boston\n",
       "1035   87000.0  Data Scientist                          ViaSat         Boston\n",
       "1036  151000.0  Data Scientist                       Think Big         Boston\n",
       "1037  128000.0  Data Scientist                      BNY Mellon         Boston\n",
       "1038  131000.0  Data Scientist                             IBM         Boston\n",
       "1039  146000.0  Data Scientist                       Microsoft         Boston\n",
       "1040   93000.0  Data Scientist             Booz Allen Hamilton         Boston\n",
       "1041  133000.0  Data Scientist                       Think Big         Boston\n",
       "1042   98000.0  Data Scientist                        MaxPoint         Boston\n",
       "1043  110000.0  Data Scientist                 Tiger Analytics         Boston\n",
       "1044  132000.0  Data Scientist                            YuMe         Boston\n",
       "1045  116000.0  Data Scientist                             FIS         Boston\n",
       "1046  143000.0  Data Scientist                          Akamai         Boston\n",
       "1047  112000.0  Data Scientist                      Amazon.com         Boston\n",
       "1048   87000.0  Data Scientist                          ViaSat         Boston\n",
       "1049  150000.0  Data Scientist                       Think Big         Boston\n",
       "1050  128000.0  Data Scientist                      BNY Mellon         Boston\n",
       "\n",
       "[1051 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing outliers i.e removing meanPay < 20000\n",
    "df = ndf[ndf['meanPay'] > 20000]\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x115b62390>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAESCAYAAAAWtRmOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115afd4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['meanPay'].hist()\n",
    "pl.suptitle(\"meanPay Histogram without outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the meanPay:  85152.4833492\n",
      "median of the meanPay:  76000.0\n",
      "stdv of the meanPay:  30048.6626528\n",
      "miminum meanPay:  21000.0\n",
      "maximum meanPay:  209000.0\n"
     ]
    }
   ],
   "source": [
    "#after removing the outliers\n",
    "print \"mean of the meanPay: \", df['meanPay'].mean()\n",
    "print \"median of the meanPay: \", df['meanPay'].median()\n",
    "print \"stdv of the meanPay: \", df['meanPay'].std()\n",
    "print \"miminum meanPay: \", df['meanPay'].min()\n",
    "print \"maximum meanPay: \", df['meanPay'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1051 entries, 0 to 1050\n",
      "Data columns (total 4 columns):\n",
      "meanPay     1051 non-null float64\n",
      "jobTitle    1051 non-null object\n",
      "company     1051 non-null object\n",
      "location    1051 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Boston   DC  New York  San Francisco\n",
      "0        0.0  0.0       0.0            1.0\n",
      "1        0.0  0.0       0.0            1.0\n",
      "2        0.0  0.0       0.0            1.0\n",
      "3        0.0  0.0       0.0            1.0\n",
      "4        0.0  0.0       0.0            1.0\n",
      "5        0.0  0.0       0.0            1.0\n",
      "6        0.0  0.0       0.0            1.0\n",
      "7        0.0  0.0       0.0            1.0\n",
      "8        0.0  0.0       0.0            1.0\n",
      "9        0.0  0.0       0.0            1.0\n",
      "10       0.0  0.0       0.0            1.0\n",
      "11       0.0  0.0       0.0            1.0\n",
      "12       0.0  0.0       0.0            1.0\n",
      "13       0.0  0.0       0.0            1.0\n",
      "14       0.0  0.0       0.0            1.0\n",
      "15       0.0  0.0       0.0            1.0\n",
      "16       0.0  0.0       0.0            1.0\n",
      "17       0.0  0.0       0.0            1.0\n",
      "18       0.0  0.0       0.0            1.0\n",
      "19       0.0  0.0       0.0            1.0\n",
      "20       0.0  0.0       0.0            1.0\n",
      "21       0.0  0.0       0.0            1.0\n",
      "22       0.0  0.0       0.0            1.0\n",
      "23       0.0  0.0       0.0            1.0\n",
      "24       0.0  0.0       0.0            1.0\n",
      "25       0.0  0.0       0.0            1.0\n",
      "26       0.0  0.0       0.0            1.0\n",
      "27       0.0  0.0       0.0            1.0\n",
      "28       0.0  0.0       0.0            1.0\n",
      "29       0.0  0.0       0.0            1.0\n",
      "...      ...  ...       ...            ...\n",
      "1021     1.0  0.0       0.0            0.0\n",
      "1022     1.0  0.0       0.0            0.0\n",
      "1023     1.0  0.0       0.0            0.0\n",
      "1024     1.0  0.0       0.0            0.0\n",
      "1025     1.0  0.0       0.0            0.0\n",
      "1026     1.0  0.0       0.0            0.0\n",
      "1027     1.0  0.0       0.0            0.0\n",
      "1028     1.0  0.0       0.0            0.0\n",
      "1029     1.0  0.0       0.0            0.0\n",
      "1030     1.0  0.0       0.0            0.0\n",
      "1031     1.0  0.0       0.0            0.0\n",
      "1032     1.0  0.0       0.0            0.0\n",
      "1033     1.0  0.0       0.0            0.0\n",
      "1034     1.0  0.0       0.0            0.0\n",
      "1035     1.0  0.0       0.0            0.0\n",
      "1036     1.0  0.0       0.0            0.0\n",
      "1037     1.0  0.0       0.0            0.0\n",
      "1038     1.0  0.0       0.0            0.0\n",
      "1039     1.0  0.0       0.0            0.0\n",
      "1040     1.0  0.0       0.0            0.0\n",
      "1041     1.0  0.0       0.0            0.0\n",
      "1042     1.0  0.0       0.0            0.0\n",
      "1043     1.0  0.0       0.0            0.0\n",
      "1044     1.0  0.0       0.0            0.0\n",
      "1045     1.0  0.0       0.0            0.0\n",
      "1046     1.0  0.0       0.0            0.0\n",
      "1047     1.0  0.0       0.0            0.0\n",
      "1048     1.0  0.0       0.0            0.0\n",
      "1049     1.0  0.0       0.0            0.0\n",
      "1050     1.0  0.0       0.0            0.0\n",
      "\n",
      "[1051 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#create dummies for the location\n",
    "\n",
    "df_location = pd.get_dummies(df['location'])\n",
    "df_location = df_location.reset_index(drop=True)\n",
    "print df_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       meanPay        jobTitle                         company       location  \\\n",
      "0      66843.0    Data Analyst                 Canvas InfoTech  San Francisco   \n",
      "1      63429.0    Data Analyst                BetaSoft Systems  San Francisco   \n",
      "2      75765.0    Data Analyst                        Deloitte  San Francisco   \n",
      "3      81972.0    Data Analyst              McKinsey & Company  San Francisco   \n",
      "4      74301.0    Data Analyst                       Accenture  San Francisco   \n",
      "5      76798.0    Data Analyst              Hitachi Consulting  San Francisco   \n",
      "6      63146.0    Data Analyst           All State Consultants  San Francisco   \n",
      "7      68889.0    Data Analyst                DGN Technologies  San Francisco   \n",
      "8      81637.0    Data Analyst              Calypso Technology  San Francisco   \n",
      "9      69434.0    Data Analyst                    DS Soft Tech  San Francisco   \n",
      "10    100753.0    Data Analyst                         Chevron  San Francisco   \n",
      "11     82388.0    Data Analyst        Pacific Gas and Electric  San Francisco   \n",
      "12     64966.0    Data Analyst                        Equinett  San Francisco   \n",
      "13     69238.0    Data Analyst                            Cswl  San Francisco   \n",
      "14     83102.0    Data Analyst                 Mahindra Satyam  San Francisco   \n",
      "15     83872.0    Data Analyst               Kaiser Permanente  San Francisco   \n",
      "16     82177.0    Data Analyst                       Visa Inc.  San Francisco   \n",
      "17     70627.0    Data Analyst                         Detecon  San Francisco   \n",
      "18     66690.0    Data Analyst             ProSwift Consulting  San Francisco   \n",
      "19    122404.0    Data Analyst                   Cisco Systems  San Francisco   \n",
      "20     87809.0    Data Analyst                     Cognilytics  San Francisco   \n",
      "21     64794.0    Data Analyst                       Macro.Net  San Francisco   \n",
      "22     85728.0    Data Analyst                          Oracle  San Francisco   \n",
      "23     66598.0    Data Analyst                       Sandlenet  San Francisco   \n",
      "24     68283.0    Data Analyst                DYNASOFT SYNERGY  San Francisco   \n",
      "25     79981.0    Data Analyst                     Wells Fargo  San Francisco   \n",
      "26     71657.0    Data Analyst                         Safeway  San Francisco   \n",
      "27     80901.0    Data Analyst                       Genentech  San Francisco   \n",
      "28     68960.0    Data Analyst  Cognizant Technology Solutions  San Francisco   \n",
      "29     63805.0    Data Analyst               Agile Informatics  San Francisco   \n",
      "...        ...             ...                             ...            ...   \n",
      "1021  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1022   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1023  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1024  126000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1025  132000.0  Data Scientist                             IBM         Boston   \n",
      "1026  144000.0  Data Scientist                       Microsoft         Boston   \n",
      "1027   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1028  136000.0  Data Scientist                       Think Big         Boston   \n",
      "1029   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1030  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1031  134000.0  Data Scientist                            YuMe         Boston   \n",
      "1032  116000.0  Data Scientist                             FIS         Boston   \n",
      "1033  142000.0  Data Scientist                          Akamai         Boston   \n",
      "1034  111000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1035   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1036  151000.0  Data Scientist                       Think Big         Boston   \n",
      "1037  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1038  131000.0  Data Scientist                             IBM         Boston   \n",
      "1039  146000.0  Data Scientist                       Microsoft         Boston   \n",
      "1040   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1041  133000.0  Data Scientist                       Think Big         Boston   \n",
      "1042   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1043  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1044  132000.0  Data Scientist                            YuMe         Boston   \n",
      "1045  116000.0  Data Scientist                             FIS         Boston   \n",
      "1046  143000.0  Data Scientist                          Akamai         Boston   \n",
      "1047  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1048   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1049  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1050  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "\n",
      "      Boston   DC  New York  San Francisco  \n",
      "0        0.0  0.0       0.0            1.0  \n",
      "1        0.0  0.0       0.0            1.0  \n",
      "2        0.0  0.0       0.0            1.0  \n",
      "3        0.0  0.0       0.0            1.0  \n",
      "4        0.0  0.0       0.0            1.0  \n",
      "5        0.0  0.0       0.0            1.0  \n",
      "6        0.0  0.0       0.0            1.0  \n",
      "7        0.0  0.0       0.0            1.0  \n",
      "8        0.0  0.0       0.0            1.0  \n",
      "9        0.0  0.0       0.0            1.0  \n",
      "10       0.0  0.0       0.0            1.0  \n",
      "11       0.0  0.0       0.0            1.0  \n",
      "12       0.0  0.0       0.0            1.0  \n",
      "13       0.0  0.0       0.0            1.0  \n",
      "14       0.0  0.0       0.0            1.0  \n",
      "15       0.0  0.0       0.0            1.0  \n",
      "16       0.0  0.0       0.0            1.0  \n",
      "17       0.0  0.0       0.0            1.0  \n",
      "18       0.0  0.0       0.0            1.0  \n",
      "19       0.0  0.0       0.0            1.0  \n",
      "20       0.0  0.0       0.0            1.0  \n",
      "21       0.0  0.0       0.0            1.0  \n",
      "22       0.0  0.0       0.0            1.0  \n",
      "23       0.0  0.0       0.0            1.0  \n",
      "24       0.0  0.0       0.0            1.0  \n",
      "25       0.0  0.0       0.0            1.0  \n",
      "26       0.0  0.0       0.0            1.0  \n",
      "27       0.0  0.0       0.0            1.0  \n",
      "28       0.0  0.0       0.0            1.0  \n",
      "29       0.0  0.0       0.0            1.0  \n",
      "...      ...  ...       ...            ...  \n",
      "1021     1.0  0.0       0.0            0.0  \n",
      "1022     1.0  0.0       0.0            0.0  \n",
      "1023     1.0  0.0       0.0            0.0  \n",
      "1024     1.0  0.0       0.0            0.0  \n",
      "1025     1.0  0.0       0.0            0.0  \n",
      "1026     1.0  0.0       0.0            0.0  \n",
      "1027     1.0  0.0       0.0            0.0  \n",
      "1028     1.0  0.0       0.0            0.0  \n",
      "1029     1.0  0.0       0.0            0.0  \n",
      "1030     1.0  0.0       0.0            0.0  \n",
      "1031     1.0  0.0       0.0            0.0  \n",
      "1032     1.0  0.0       0.0            0.0  \n",
      "1033     1.0  0.0       0.0            0.0  \n",
      "1034     1.0  0.0       0.0            0.0  \n",
      "1035     1.0  0.0       0.0            0.0  \n",
      "1036     1.0  0.0       0.0            0.0  \n",
      "1037     1.0  0.0       0.0            0.0  \n",
      "1038     1.0  0.0       0.0            0.0  \n",
      "1039     1.0  0.0       0.0            0.0  \n",
      "1040     1.0  0.0       0.0            0.0  \n",
      "1041     1.0  0.0       0.0            0.0  \n",
      "1042     1.0  0.0       0.0            0.0  \n",
      "1043     1.0  0.0       0.0            0.0  \n",
      "1044     1.0  0.0       0.0            0.0  \n",
      "1045     1.0  0.0       0.0            0.0  \n",
      "1046     1.0  0.0       0.0            0.0  \n",
      "1047     1.0  0.0       0.0            0.0  \n",
      "1048     1.0  0.0       0.0            0.0  \n",
      "1049     1.0  0.0       0.0            0.0  \n",
      "1050     1.0  0.0       0.0            0.0  \n",
      "\n",
      "[1051 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#join the location dummies to the existing data frame\n",
    "new_df= pd.concat([df,df_location], axis = 1)\n",
    "print new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       meanPay        jobTitle                         company       location  \\\n",
      "0      66843.0    Data Analyst                 Canvas InfoTech  San Francisco   \n",
      "1      63429.0    Data Analyst                BetaSoft Systems  San Francisco   \n",
      "2      75765.0    Data Analyst                        Deloitte  San Francisco   \n",
      "3      81972.0    Data Analyst              McKinsey & Company  San Francisco   \n",
      "4      74301.0    Data Analyst                       Accenture  San Francisco   \n",
      "5      76798.0    Data Analyst              Hitachi Consulting  San Francisco   \n",
      "6      63146.0    Data Analyst           All State Consultants  San Francisco   \n",
      "7      68889.0    Data Analyst                DGN Technologies  San Francisco   \n",
      "8      81637.0    Data Analyst              Calypso Technology  San Francisco   \n",
      "9      69434.0    Data Analyst                    DS Soft Tech  San Francisco   \n",
      "10    100753.0    Data Analyst                         Chevron  San Francisco   \n",
      "11     82388.0    Data Analyst        Pacific Gas and Electric  San Francisco   \n",
      "12     64966.0    Data Analyst                        Equinett  San Francisco   \n",
      "13     69238.0    Data Analyst                            Cswl  San Francisco   \n",
      "14     83102.0    Data Analyst                 Mahindra Satyam  San Francisco   \n",
      "15     83872.0    Data Analyst               Kaiser Permanente  San Francisco   \n",
      "16     82177.0    Data Analyst                       Visa Inc.  San Francisco   \n",
      "17     70627.0    Data Analyst                         Detecon  San Francisco   \n",
      "18     66690.0    Data Analyst             ProSwift Consulting  San Francisco   \n",
      "19    122404.0    Data Analyst                   Cisco Systems  San Francisco   \n",
      "20     87809.0    Data Analyst                     Cognilytics  San Francisco   \n",
      "21     64794.0    Data Analyst                       Macro.Net  San Francisco   \n",
      "22     85728.0    Data Analyst                          Oracle  San Francisco   \n",
      "23     66598.0    Data Analyst                       Sandlenet  San Francisco   \n",
      "24     68283.0    Data Analyst                DYNASOFT SYNERGY  San Francisco   \n",
      "25     79981.0    Data Analyst                     Wells Fargo  San Francisco   \n",
      "26     71657.0    Data Analyst                         Safeway  San Francisco   \n",
      "27     80901.0    Data Analyst                       Genentech  San Francisco   \n",
      "28     68960.0    Data Analyst  Cognizant Technology Solutions  San Francisco   \n",
      "29     63805.0    Data Analyst               Agile Informatics  San Francisco   \n",
      "...        ...             ...                             ...            ...   \n",
      "1021  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1022   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1023  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1024  126000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1025  132000.0  Data Scientist                             IBM         Boston   \n",
      "1026  144000.0  Data Scientist                       Microsoft         Boston   \n",
      "1027   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1028  136000.0  Data Scientist                       Think Big         Boston   \n",
      "1029   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1030  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1031  134000.0  Data Scientist                            YuMe         Boston   \n",
      "1032  116000.0  Data Scientist                             FIS         Boston   \n",
      "1033  142000.0  Data Scientist                          Akamai         Boston   \n",
      "1034  111000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1035   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1036  151000.0  Data Scientist                       Think Big         Boston   \n",
      "1037  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1038  131000.0  Data Scientist                             IBM         Boston   \n",
      "1039  146000.0  Data Scientist                       Microsoft         Boston   \n",
      "1040   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1041  133000.0  Data Scientist                       Think Big         Boston   \n",
      "1042   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1043  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1044  132000.0  Data Scientist                            YuMe         Boston   \n",
      "1045  116000.0  Data Scientist                             FIS         Boston   \n",
      "1046  143000.0  Data Scientist                          Akamai         Boston   \n",
      "1047  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1048   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1049  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1050  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "\n",
      "      Boston   DC  New York  San Francisco  Pay  \n",
      "0        0.0  0.0       0.0            1.0    0  \n",
      "1        0.0  0.0       0.0            1.0    0  \n",
      "2        0.0  0.0       0.0            1.0    0  \n",
      "3        0.0  0.0       0.0            1.0    0  \n",
      "4        0.0  0.0       0.0            1.0    0  \n",
      "5        0.0  0.0       0.0            1.0    0  \n",
      "6        0.0  0.0       0.0            1.0    0  \n",
      "7        0.0  0.0       0.0            1.0    0  \n",
      "8        0.0  0.0       0.0            1.0    0  \n",
      "9        0.0  0.0       0.0            1.0    0  \n",
      "10       0.0  0.0       0.0            1.0    0  \n",
      "11       0.0  0.0       0.0            1.0    0  \n",
      "12       0.0  0.0       0.0            1.0    0  \n",
      "13       0.0  0.0       0.0            1.0    0  \n",
      "14       0.0  0.0       0.0            1.0    0  \n",
      "15       0.0  0.0       0.0            1.0    0  \n",
      "16       0.0  0.0       0.0            1.0    0  \n",
      "17       0.0  0.0       0.0            1.0    0  \n",
      "18       0.0  0.0       0.0            1.0    0  \n",
      "19       0.0  0.0       0.0            1.0    0  \n",
      "20       0.0  0.0       0.0            1.0    0  \n",
      "21       0.0  0.0       0.0            1.0    0  \n",
      "22       0.0  0.0       0.0            1.0    0  \n",
      "23       0.0  0.0       0.0            1.0    0  \n",
      "24       0.0  0.0       0.0            1.0    0  \n",
      "25       0.0  0.0       0.0            1.0    0  \n",
      "26       0.0  0.0       0.0            1.0    0  \n",
      "27       0.0  0.0       0.0            1.0    0  \n",
      "28       0.0  0.0       0.0            1.0    0  \n",
      "29       0.0  0.0       0.0            1.0    0  \n",
      "...      ...  ...       ...            ...  ...  \n",
      "1021     1.0  0.0       0.0            0.0    0  \n",
      "1022     1.0  0.0       0.0            0.0    0  \n",
      "1023     1.0  0.0       0.0            0.0    0  \n",
      "1024     1.0  0.0       0.0            0.0    0  \n",
      "1025     1.0  0.0       0.0            0.0    0  \n",
      "1026     1.0  0.0       0.0            0.0    0  \n",
      "1027     1.0  0.0       0.0            0.0    0  \n",
      "1028     1.0  0.0       0.0            0.0    0  \n",
      "1029     1.0  0.0       0.0            0.0    0  \n",
      "1030     1.0  0.0       0.0            0.0    0  \n",
      "1031     1.0  0.0       0.0            0.0    0  \n",
      "1032     1.0  0.0       0.0            0.0    0  \n",
      "1033     1.0  0.0       0.0            0.0    0  \n",
      "1034     1.0  0.0       0.0            0.0    0  \n",
      "1035     1.0  0.0       0.0            0.0    0  \n",
      "1036     1.0  0.0       0.0            0.0    0  \n",
      "1037     1.0  0.0       0.0            0.0    0  \n",
      "1038     1.0  0.0       0.0            0.0    0  \n",
      "1039     1.0  0.0       0.0            0.0    0  \n",
      "1040     1.0  0.0       0.0            0.0    0  \n",
      "1041     1.0  0.0       0.0            0.0    0  \n",
      "1042     1.0  0.0       0.0            0.0    0  \n",
      "1043     1.0  0.0       0.0            0.0    0  \n",
      "1044     1.0  0.0       0.0            0.0    0  \n",
      "1045     1.0  0.0       0.0            0.0    0  \n",
      "1046     1.0  0.0       0.0            0.0    0  \n",
      "1047     1.0  0.0       0.0            0.0    0  \n",
      "1048     1.0  0.0       0.0            0.0    0  \n",
      "1049     1.0  0.0       0.0            0.0    0  \n",
      "1050     1.0  0.0       0.0            0.0    0  \n",
      "\n",
      "[1051 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#introduce a new column 'Pay'. 'Pay' would be the dependent variable for the model\n",
    "new_df['Pay']=0\n",
    "print new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       meanPay        jobTitle                         company       location  \\\n",
      "0      66843.0    Data Analyst                 Canvas InfoTech  San Francisco   \n",
      "1      63429.0    Data Analyst                BetaSoft Systems  San Francisco   \n",
      "2      75765.0    Data Analyst                        Deloitte  San Francisco   \n",
      "3      81972.0    Data Analyst              McKinsey & Company  San Francisco   \n",
      "4      74301.0    Data Analyst                       Accenture  San Francisco   \n",
      "5      76798.0    Data Analyst              Hitachi Consulting  San Francisco   \n",
      "6      63146.0    Data Analyst           All State Consultants  San Francisco   \n",
      "7      68889.0    Data Analyst                DGN Technologies  San Francisco   \n",
      "8      81637.0    Data Analyst              Calypso Technology  San Francisco   \n",
      "9      69434.0    Data Analyst                    DS Soft Tech  San Francisco   \n",
      "10    100753.0    Data Analyst                         Chevron  San Francisco   \n",
      "11     82388.0    Data Analyst        Pacific Gas and Electric  San Francisco   \n",
      "12     64966.0    Data Analyst                        Equinett  San Francisco   \n",
      "13     69238.0    Data Analyst                            Cswl  San Francisco   \n",
      "14     83102.0    Data Analyst                 Mahindra Satyam  San Francisco   \n",
      "15     83872.0    Data Analyst               Kaiser Permanente  San Francisco   \n",
      "16     82177.0    Data Analyst                       Visa Inc.  San Francisco   \n",
      "17     70627.0    Data Analyst                         Detecon  San Francisco   \n",
      "18     66690.0    Data Analyst             ProSwift Consulting  San Francisco   \n",
      "19    122404.0    Data Analyst                   Cisco Systems  San Francisco   \n",
      "20     87809.0    Data Analyst                     Cognilytics  San Francisco   \n",
      "21     64794.0    Data Analyst                       Macro.Net  San Francisco   \n",
      "22     85728.0    Data Analyst                          Oracle  San Francisco   \n",
      "23     66598.0    Data Analyst                       Sandlenet  San Francisco   \n",
      "24     68283.0    Data Analyst                DYNASOFT SYNERGY  San Francisco   \n",
      "25     79981.0    Data Analyst                     Wells Fargo  San Francisco   \n",
      "26     71657.0    Data Analyst                         Safeway  San Francisco   \n",
      "27     80901.0    Data Analyst                       Genentech  San Francisco   \n",
      "28     68960.0    Data Analyst  Cognizant Technology Solutions  San Francisco   \n",
      "29     63805.0    Data Analyst               Agile Informatics  San Francisco   \n",
      "...        ...             ...                             ...            ...   \n",
      "1021  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1022   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1023  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1024  126000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1025  132000.0  Data Scientist                             IBM         Boston   \n",
      "1026  144000.0  Data Scientist                       Microsoft         Boston   \n",
      "1027   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1028  136000.0  Data Scientist                       Think Big         Boston   \n",
      "1029   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1030  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1031  134000.0  Data Scientist                            YuMe         Boston   \n",
      "1032  116000.0  Data Scientist                             FIS         Boston   \n",
      "1033  142000.0  Data Scientist                          Akamai         Boston   \n",
      "1034  111000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1035   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1036  151000.0  Data Scientist                       Think Big         Boston   \n",
      "1037  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "1038  131000.0  Data Scientist                             IBM         Boston   \n",
      "1039  146000.0  Data Scientist                       Microsoft         Boston   \n",
      "1040   93000.0  Data Scientist             Booz Allen Hamilton         Boston   \n",
      "1041  133000.0  Data Scientist                       Think Big         Boston   \n",
      "1042   98000.0  Data Scientist                        MaxPoint         Boston   \n",
      "1043  110000.0  Data Scientist                 Tiger Analytics         Boston   \n",
      "1044  132000.0  Data Scientist                            YuMe         Boston   \n",
      "1045  116000.0  Data Scientist                             FIS         Boston   \n",
      "1046  143000.0  Data Scientist                          Akamai         Boston   \n",
      "1047  112000.0  Data Scientist                      Amazon.com         Boston   \n",
      "1048   87000.0  Data Scientist                          ViaSat         Boston   \n",
      "1049  150000.0  Data Scientist                       Think Big         Boston   \n",
      "1050  128000.0  Data Scientist                      BNY Mellon         Boston   \n",
      "\n",
      "      Boston   DC  New York  San Francisco  Pay  \n",
      "0        0.0  0.0       0.0            1.0    0  \n",
      "1        0.0  0.0       0.0            1.0    0  \n",
      "2        0.0  0.0       0.0            1.0    0  \n",
      "3        0.0  0.0       0.0            1.0    1  \n",
      "4        0.0  0.0       0.0            1.0    0  \n",
      "5        0.0  0.0       0.0            1.0    0  \n",
      "6        0.0  0.0       0.0            1.0    0  \n",
      "7        0.0  0.0       0.0            1.0    0  \n",
      "8        0.0  0.0       0.0            1.0    1  \n",
      "9        0.0  0.0       0.0            1.0    0  \n",
      "10       0.0  0.0       0.0            1.0    1  \n",
      "11       0.0  0.0       0.0            1.0    1  \n",
      "12       0.0  0.0       0.0            1.0    0  \n",
      "13       0.0  0.0       0.0            1.0    0  \n",
      "14       0.0  0.0       0.0            1.0    1  \n",
      "15       0.0  0.0       0.0            1.0    1  \n",
      "16       0.0  0.0       0.0            1.0    1  \n",
      "17       0.0  0.0       0.0            1.0    0  \n",
      "18       0.0  0.0       0.0            1.0    0  \n",
      "19       0.0  0.0       0.0            1.0    1  \n",
      "20       0.0  0.0       0.0            1.0    1  \n",
      "21       0.0  0.0       0.0            1.0    0  \n",
      "22       0.0  0.0       0.0            1.0    1  \n",
      "23       0.0  0.0       0.0            1.0    0  \n",
      "24       0.0  0.0       0.0            1.0    0  \n",
      "25       0.0  0.0       0.0            1.0    0  \n",
      "26       0.0  0.0       0.0            1.0    0  \n",
      "27       0.0  0.0       0.0            1.0    1  \n",
      "28       0.0  0.0       0.0            1.0    0  \n",
      "29       0.0  0.0       0.0            1.0    0  \n",
      "...      ...  ...       ...            ...  ...  \n",
      "1021     1.0  0.0       0.0            0.0    1  \n",
      "1022     1.0  0.0       0.0            0.0    1  \n",
      "1023     1.0  0.0       0.0            0.0    1  \n",
      "1024     1.0  0.0       0.0            0.0    1  \n",
      "1025     1.0  0.0       0.0            0.0    1  \n",
      "1026     1.0  0.0       0.0            0.0    1  \n",
      "1027     1.0  0.0       0.0            0.0    1  \n",
      "1028     1.0  0.0       0.0            0.0    1  \n",
      "1029     1.0  0.0       0.0            0.0    1  \n",
      "1030     1.0  0.0       0.0            0.0    1  \n",
      "1031     1.0  0.0       0.0            0.0    1  \n",
      "1032     1.0  0.0       0.0            0.0    1  \n",
      "1033     1.0  0.0       0.0            0.0    1  \n",
      "1034     1.0  0.0       0.0            0.0    1  \n",
      "1035     1.0  0.0       0.0            0.0    1  \n",
      "1036     1.0  0.0       0.0            0.0    1  \n",
      "1037     1.0  0.0       0.0            0.0    1  \n",
      "1038     1.0  0.0       0.0            0.0    1  \n",
      "1039     1.0  0.0       0.0            0.0    1  \n",
      "1040     1.0  0.0       0.0            0.0    1  \n",
      "1041     1.0  0.0       0.0            0.0    1  \n",
      "1042     1.0  0.0       0.0            0.0    1  \n",
      "1043     1.0  0.0       0.0            0.0    1  \n",
      "1044     1.0  0.0       0.0            0.0    1  \n",
      "1045     1.0  0.0       0.0            0.0    1  \n",
      "1046     1.0  0.0       0.0            0.0    1  \n",
      "1047     1.0  0.0       0.0            0.0    1  \n",
      "1048     1.0  0.0       0.0            0.0    1  \n",
      "1049     1.0  0.0       0.0            0.0    1  \n",
      "1050     1.0  0.0       0.0            0.0    1  \n",
      "\n",
      "[1051 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating two buckets for meanPay. less than 80K is 0 and greater than 80K is 1\n",
    "\n",
    "new_df.ix[new_df['meanPay'] > 80000,'Pay'] = 1\n",
    "print new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using statsmodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a new data frame with the location dummies and the \"Pay\" column\n",
    "\n",
    "import statsmodels.api as sm\n",
    "location_df = new_df[['Pay', 'Boston', 'DC', 'New York', 'San Francisco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stats model has no intercept\n",
    "pd.options.mode.chained_assignment = None\n",
    "import statsmodels.api as sm\n",
    "location_df[\"intercept\"] = 1.0\n",
    "train_cols = location_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Boston', u'DC', u'New York', u'San Francisco', u'intercept'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boston', 'DC', 'New York', 'San Francisco', 'intercept']\n"
     ]
    }
   ],
   "source": [
    "print list(train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pay</th>\n",
       "      <th>Boston</th>\n",
       "      <th>DC</th>\n",
       "      <th>New York</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pay  Boston   DC  New York  San Francisco  intercept\n",
       "0    0     0.0  0.0       0.0            1.0        1.0\n",
       "1    0     0.0  0.0       0.0            1.0        1.0\n",
       "2    0     0.0  0.0       0.0            1.0        1.0\n",
       "3    1     0.0  0.0       0.0            1.0        1.0\n",
       "4    0     0.0  0.0       0.0            1.0        1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit = sm.Logit(location_df['Pay'], location_df[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664631\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.032</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>        <td>Pay</td>             <td>AIC:</td>         <td>1405.0549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2016-10-18 11:05</td>       <td>BIC:</td>         <td>1424.8848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1051</td>        <td>Log-Likelihood:</td>    <td>-698.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>        <td>-721.52</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1047</td>         <td>LLR p-value:</td>    <td>5.7300e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>5.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>    <td>-0.7362</td>  <td>0.1735</td>  <td>-4.2429</td> <td>0.0000</td> <td>-1.0763</td> <td>-0.3961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC</th>        <td>-1.2397</td>  <td>0.1926</td>  <td>-6.4368</td> <td>0.0000</td> <td>-1.6171</td> <td>-0.8622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>  <td>-0.5566</td>  <td>0.1699</td>  <td>-3.2760</td> <td>0.0011</td> <td>-0.8896</td> <td>-0.2236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>0.3524</td>   <td>0.1212</td>  <td>2.9080</td>  <td>0.0036</td> <td>0.1149</td>  <td>0.5898</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.032     \n",
       "Dependent Variable: Pay              AIC:              1405.0549 \n",
       "Date:               2016-10-18 11:05 BIC:              1424.8848 \n",
       "No. Observations:   1051             Log-Likelihood:   -698.53   \n",
       "Df Model:           3                LL-Null:          -721.52   \n",
       "Df Residuals:       1047             LLR p-value:      5.7300e-10\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     5.0000                                       \n",
       "------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "Boston        -0.7362    0.1735  -4.2429  0.0000  -1.0763  -0.3961\n",
       "DC            -1.2397    0.1926  -6.4368  0.0000  -1.6171  -0.8622\n",
       "New York      -0.5566    0.1699  -3.2760  0.0011  -0.8896  -0.2236\n",
       "intercept      0.3524    0.1212   2.9080  0.0036   0.1149   0.5898\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logistic regression with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Data Analyst  Data Scientist\n",
      "0              1.0             0.0\n",
      "1              1.0             0.0\n",
      "2              1.0             0.0\n",
      "3              1.0             0.0\n",
      "4              1.0             0.0\n",
      "5              1.0             0.0\n",
      "6              1.0             0.0\n",
      "7              1.0             0.0\n",
      "8              1.0             0.0\n",
      "9              1.0             0.0\n",
      "10             1.0             0.0\n",
      "11             1.0             0.0\n",
      "12             1.0             0.0\n",
      "13             1.0             0.0\n",
      "14             1.0             0.0\n",
      "15             1.0             0.0\n",
      "16             1.0             0.0\n",
      "17             1.0             0.0\n",
      "18             1.0             0.0\n",
      "19             1.0             0.0\n",
      "20             1.0             0.0\n",
      "21             1.0             0.0\n",
      "22             1.0             0.0\n",
      "23             1.0             0.0\n",
      "24             1.0             0.0\n",
      "25             1.0             0.0\n",
      "26             1.0             0.0\n",
      "27             1.0             0.0\n",
      "28             1.0             0.0\n",
      "29             1.0             0.0\n",
      "...            ...             ...\n",
      "1021           0.0             1.0\n",
      "1022           0.0             1.0\n",
      "1023           0.0             1.0\n",
      "1024           0.0             1.0\n",
      "1025           0.0             1.0\n",
      "1026           0.0             1.0\n",
      "1027           0.0             1.0\n",
      "1028           0.0             1.0\n",
      "1029           0.0             1.0\n",
      "1030           0.0             1.0\n",
      "1031           0.0             1.0\n",
      "1032           0.0             1.0\n",
      "1033           0.0             1.0\n",
      "1034           0.0             1.0\n",
      "1035           0.0             1.0\n",
      "1036           0.0             1.0\n",
      "1037           0.0             1.0\n",
      "1038           0.0             1.0\n",
      "1039           0.0             1.0\n",
      "1040           0.0             1.0\n",
      "1041           0.0             1.0\n",
      "1042           0.0             1.0\n",
      "1043           0.0             1.0\n",
      "1044           0.0             1.0\n",
      "1045           0.0             1.0\n",
      "1046           0.0             1.0\n",
      "1047           0.0             1.0\n",
      "1048           0.0             1.0\n",
      "1049           0.0             1.0\n",
      "1050           0.0             1.0\n",
      "\n",
      "[1051 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#create dummies for the job titles\n",
    "\n",
    "df_title = pd.get_dummies(df['jobTitle'])\n",
    "df_title = df_title.reset_index(drop=True)\n",
    "print df_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pay  Boston   DC  New York  San Francisco\n",
      "0       0     0.0  0.0       0.0            1.0\n",
      "1       0     0.0  0.0       0.0            1.0\n",
      "2       0     0.0  0.0       0.0            1.0\n",
      "3       1     0.0  0.0       0.0            1.0\n",
      "4       0     0.0  0.0       0.0            1.0\n",
      "5       0     0.0  0.0       0.0            1.0\n",
      "6       0     0.0  0.0       0.0            1.0\n",
      "7       0     0.0  0.0       0.0            1.0\n",
      "8       1     0.0  0.0       0.0            1.0\n",
      "9       0     0.0  0.0       0.0            1.0\n",
      "10      1     0.0  0.0       0.0            1.0\n",
      "11      1     0.0  0.0       0.0            1.0\n",
      "12      0     0.0  0.0       0.0            1.0\n",
      "13      0     0.0  0.0       0.0            1.0\n",
      "14      1     0.0  0.0       0.0            1.0\n",
      "15      1     0.0  0.0       0.0            1.0\n",
      "16      1     0.0  0.0       0.0            1.0\n",
      "17      0     0.0  0.0       0.0            1.0\n",
      "18      0     0.0  0.0       0.0            1.0\n",
      "19      1     0.0  0.0       0.0            1.0\n",
      "20      1     0.0  0.0       0.0            1.0\n",
      "21      0     0.0  0.0       0.0            1.0\n",
      "22      1     0.0  0.0       0.0            1.0\n",
      "23      0     0.0  0.0       0.0            1.0\n",
      "24      0     0.0  0.0       0.0            1.0\n",
      "25      0     0.0  0.0       0.0            1.0\n",
      "26      0     0.0  0.0       0.0            1.0\n",
      "27      1     0.0  0.0       0.0            1.0\n",
      "28      0     0.0  0.0       0.0            1.0\n",
      "29      0     0.0  0.0       0.0            1.0\n",
      "...   ...     ...  ...       ...            ...\n",
      "1021    1     1.0  0.0       0.0            0.0\n",
      "1022    1     1.0  0.0       0.0            0.0\n",
      "1023    1     1.0  0.0       0.0            0.0\n",
      "1024    1     1.0  0.0       0.0            0.0\n",
      "1025    1     1.0  0.0       0.0            0.0\n",
      "1026    1     1.0  0.0       0.0            0.0\n",
      "1027    1     1.0  0.0       0.0            0.0\n",
      "1028    1     1.0  0.0       0.0            0.0\n",
      "1029    1     1.0  0.0       0.0            0.0\n",
      "1030    1     1.0  0.0       0.0            0.0\n",
      "1031    1     1.0  0.0       0.0            0.0\n",
      "1032    1     1.0  0.0       0.0            0.0\n",
      "1033    1     1.0  0.0       0.0            0.0\n",
      "1034    1     1.0  0.0       0.0            0.0\n",
      "1035    1     1.0  0.0       0.0            0.0\n",
      "1036    1     1.0  0.0       0.0            0.0\n",
      "1037    1     1.0  0.0       0.0            0.0\n",
      "1038    1     1.0  0.0       0.0            0.0\n",
      "1039    1     1.0  0.0       0.0            0.0\n",
      "1040    1     1.0  0.0       0.0            0.0\n",
      "1041    1     1.0  0.0       0.0            0.0\n",
      "1042    1     1.0  0.0       0.0            0.0\n",
      "1043    1     1.0  0.0       0.0            0.0\n",
      "1044    1     1.0  0.0       0.0            0.0\n",
      "1045    1     1.0  0.0       0.0            0.0\n",
      "1046    1     1.0  0.0       0.0            0.0\n",
      "1047    1     1.0  0.0       0.0            0.0\n",
      "1048    1     1.0  0.0       0.0            0.0\n",
      "1049    1     1.0  0.0       0.0            0.0\n",
      "1050    1     1.0  0.0       0.0            0.0\n",
      "\n",
      "[1051 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_4location = new_df[['Pay', 'Boston', 'DC', 'New York', 'San Francisco']]\n",
    "print df_4location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pay  Boston   DC  New York  San Francisco  Data Analyst  Data Scientist\n",
      "0       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "1       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "2       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "3       1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "4       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "5       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "6       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "7       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "8       1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "9       0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "10      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "11      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "12      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "13      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "14      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "15      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "16      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "17      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "18      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "19      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "20      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "21      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "22      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "23      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "24      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "25      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "26      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "27      1     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "28      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "29      0     0.0  0.0       0.0            1.0           1.0             0.0\n",
      "...   ...     ...  ...       ...            ...           ...             ...\n",
      "1021    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1022    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1023    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1024    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1025    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1026    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1027    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1028    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1029    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1030    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1031    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1032    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1033    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1034    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1035    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1036    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1037    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1038    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1039    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1040    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1041    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1042    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1043    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1044    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1045    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1046    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1047    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1048    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1049    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "1050    1     1.0  0.0       0.0            0.0           0.0             1.0\n",
      "\n",
      "[1051 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#join the location dummies from location_df1 and df_title to get a new data frame with dummies\n",
    "new_df1= pd.concat([df_4location,df_title], axis = 1)\n",
    "print new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Boston', u'DC', u'New York', u'San Francisco', u'Data Analyst',\n",
      "       u'Data Scientist'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#setting the data for the logistic regression\n",
    "\n",
    "y = new_df1['Pay']\n",
    "tcols = new_df1.columns[1:]\n",
    "\n",
    "print tcols\n",
    "\n",
    "X = new_df1[tcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the model:  0.810656517602\n"
     ]
    }
   ],
   "source": [
    "# instantiate a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "print \"The score of the model: \", model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442435775452\n"
     ]
    }
   ],
   "source": [
    "# 44% of the jobs pay over 80K\n",
    "print y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston</td>\n",
       "      <td>[-0.128888914152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC</td>\n",
       "      <td>[-0.195295043737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>[-0.105317349757]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>[0.81047244054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[-1.65889801317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[2.03986914606]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                  1\n",
       "0          Boston  [-0.128888914152]\n",
       "1              DC  [-0.195295043737]\n",
       "2        New York  [-0.105317349757]\n",
       "3   San Francisco    [0.81047244054]\n",
       "4    Data Analyst   [-1.65889801317]\n",
       "5  Data Scientist    [2.03986914606]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets examine the co-efficients\n",
    "\n",
    "pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaliation of the model using a Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict class labels for the test set\n",
    "predicted = model2.predict(X_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.11272139  0.88727861]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.04249712  0.95750288]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.82004027  0.17995973]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.09027179  0.90972821]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.78066386  0.21933614]\n",
      " [ 0.09738391  0.90261609]\n",
      " [ 0.79465618  0.20534382]\n",
      " [ 0.61419196  0.38580804]\n",
      " [ 0.82004027  0.17995973]]\n"
     ]
    }
   ],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816455696203\n",
      "0.8328125\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[170   6]\n",
      " [ 52  88]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.97      0.85       176\n",
      "          1       0.94      0.63      0.75       140\n",
      "\n",
      "avg / total       0.84      0.82      0.81       316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55660377  0.55660377  0.55660377  0.66037736  1.          0.99047619\n",
      "  1.          1.          1.          0.79807692]\n",
      "0.81187417928\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Boston', u'DC', u'New York', u'San Francisco', u'Data Analyst',\n",
      "       u'Data Scientist'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print tcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "pred =np.zeros(6)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to predict salary of Data Scientist in NY\n",
    "pred[2]=1\n",
    "pred[5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.08984549,  0.91015451]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary of Project 4: Salary Prediction for Data Professionals\n",
    "\n",
    "In this project we are trying to gauge the industry factors that influence the pay scale of professionals in the field of Data Science. This information is considered to be a valuable information for hiring firms. \n",
    "\n",
    "We used webscrapping methods to collect the salary information from the web, converted the data into csv and have imported the data using pandas into a dataframe.\n",
    "\n",
    "The independent variables for the model are 'location' and 'job title'. The dependent variable for the model is 'pay' or 'salary of the individual'. Hence, according to the model, pay of an individual is influenced by the job title they hold and the location of their work. \n",
    "\n",
    "We have four work place locations: Boston, DC, New York, and San Francisco. We had a number of job titles in our original data which we have grouped into two buckets: Data Analyst and Data Scientist.\n",
    "\n",
    "\n",
    "Classification model has been applied to the data by creating binary variables. Analysis has been performed by  Logistic regression using Statsmodel as well as scikit learn.\n",
    "\n",
    "We have about 1110 rows of data for analysis. The following is the histogram of the pay(meanPay is the name of the column in the dataset) which presents the pay distribution.\n",
    "\n",
    "![](https://dpalit.github.io/images/project4_histogram1.png)\n",
    "\n",
    "\n",
    "The pay that is less than $20,000 has been considered as an outlier and has been removed from the dataset. The following histogram presents the pay distribution without the outliers.\n",
    "\n",
    "![](https://dpalit.github.io/images/project4_histogram2.png)\n",
    "\n",
    "The average pay has been calculate as $85,152.\n",
    "The median pay has been calculated as $76,000.\n",
    "Their is a standard deviation of 30048.\n",
    "\n",
    "For binary classification, the cut of has been taken as 80,000. Pay less than 80K has been classified as low (denoted 0) and a pay above 80K has been classified as high (denoted 1).\n",
    "\n",
    "The mean of the data is 44% i.e. 44% of the positions have  a pay above 80K.\n",
    "\n",
    "In scikit learn, a model score of 81% has been obtained. \n",
    "\n",
    "The co-efficients of the model are:\n",
    "\n",
    "| 0 | 1 | \n",
    "|:-:|---|\n",
    "| Boston | -0.128888914152 |\n",
    "| DC | -0.195295043737 | \n",
    "| New York\t| -0.105317349757 | \n",
    "| San Francisco | 0.81047244054 |\n",
    "| Data Analyst | -1.65889801317 |\n",
    "| Data Scientist | 2.03986914606 | \n",
    " \n",
    " \n",
    "# Prediction: \n",
    "\n",
    "We tried to predict the salary of a Data Scientist in New York using the model.\n",
    "\n",
    "The model predicted that the probability of finding a position as a Data Scientist in New York is 91%.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
